{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evluating the embeddings\n",
    "Loading of the data, adding the features to <italics>original_features<italics> and the training of the model is done using this link: https://towardsdatascience.com/machine-learning-with-datetime-feature-engineering-predicting-healthcare-appointment-no-shows-5e4ca3a85f96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from Timestamp2Vec_Model.helper_functions import *\n",
    "from Timestamp2Vec_Model.Timestamp2Vec import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "SEED = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "Loading the Medical Appointment No Shows Data Set, from this link https://www.kaggle.com/datasets/joniarroba/noshowappointments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating features for timestamps vectorized by Timestamp2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = os.path.join(os.path.join(os.path.join(os.environ['USERPROFILE']), 'Desktop'), 'data_thesis')\n",
    "\n",
    "# load the data\n",
    "df = pd.read_csv(data_location + \"/KaggleV2-May-2016.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "timestamp2vec = Timestamp2Vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduled_day_vector = timestamp2vec(df[\"ScheduledDay\"])\n",
    "apppointment_day_vector = timestamp2vec(df[\"AppointmentDay\"])\n",
    "diff_day = apppointment_day_vector - scheduled_day_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(scheduled_day_vector.shape[-1]):\n",
    "    df[\"latent_var\" + str(i + 1) + \"_scheduled\"] = scheduled_day_vector[:, i]\n",
    "    df[\"latent_var\" + str(i + 1) + \"_appointment\"] = apppointment_day_vector[:, i]\n",
    "    df[\"latent_var\" + str(i + 1) + \"_delta\"] = diff_day[:, i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features according to the link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"OUTPUT_LABEL\"] = (df[\"No-show\"] == (\"Yes\")).astype(int)\n",
    "\n",
    "df[\"ScheduledDay\"] = pd.to_datetime(df[\"ScheduledDay\"], format = \"%Y-%m-%dT%H:%M:%SZ\", errors = \"coerce\")\n",
    "df[\"AppointmentDay\"] = pd.to_datetime(df[\"AppointmentDay\"],  format = \"%Y-%m-%dT%H:%M:%SZ\", errors = \"coerce\")\n",
    "df[\"AppointmentDay\"] = df[\"AppointmentDay\"] +pd.Timedelta(\"1d\") - pd.Timedelta(\"1s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gideo\\AppData\\Local\\Temp\\ipykernel_17856\\2303329548.py:3: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  df[\"ScheduledDay_week\"] = df[\"ScheduledDay\"].dt.week\n",
      "C:\\Users\\gideo\\AppData\\Local\\Temp\\ipykernel_17856\\2303329548.py:10: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  df[\"AppointmentDay_week\"] = df[\"AppointmentDay\"].dt.week\n"
     ]
    }
   ],
   "source": [
    "df[\"ScheduledDay_year\"] = df[\"ScheduledDay\"].dt.year\n",
    "df[\"ScheduledDay_month\"] = df[\"ScheduledDay\"].dt.month\n",
    "df[\"ScheduledDay_week\"] = df[\"ScheduledDay\"].dt.week\n",
    "df[\"ScheduledDay_day\"] = df[\"ScheduledDay\"].dt.day\n",
    "df[\"ScheduledDay_hour\"] = df[\"ScheduledDay\"].dt.hour\n",
    "df[\"ScheduledDay_minute\"] = df[\"ScheduledDay\"].dt.minute\n",
    "df[\"ScheduledDay_dayofweek\"] = df[\"ScheduledDay\"].dt.dayofweek\n",
    "df[\"AppointmentDay_year\"] = df[\"AppointmentDay\"].dt.year\n",
    "df[\"AppointmentDay_month\"] = df[\"AppointmentDay\"].dt.month\n",
    "df[\"AppointmentDay_week\"] = df[\"AppointmentDay\"].dt.week\n",
    "df[\"AppointmentDay_day\"] = df[\"AppointmentDay\"].dt.day\n",
    "df[\"AppointmentDay_hour\"] = df[\"AppointmentDay\"].dt.hour\n",
    "df[\"AppointmentDay_minute\"] = df[\"AppointmentDay\"].dt.minute\n",
    "df[\"AppointmentDay_dayofweek\"] = df[\"AppointmentDay\"].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"delta_days\"] = (df[\"AppointmentDay\"]-df[\"ScheduledDay\"]).dt.total_seconds()/(60*60*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "def calc_specificity(y_actual, y_pred, thresh=0.201):\n",
    "    # calculates specificity\n",
    "    return sum((y_pred < thresh) & (y_actual == 0)) /sum(y_actual ==0)\n",
    "\n",
    "def calc_prevalence(y):\n",
    "    return (sum(y)/len(y))\n",
    "\n",
    "def print_report(y_actual, y_pred, thresh=0.201):\n",
    "    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n",
    "    recall = recall_score(y_actual, (y_pred > thresh))\n",
    "    precision = precision_score(y_actual, (y_pred > thresh))\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_normal, acc_embed_only, acc_normal_embed = [], [], []\n",
    "prec_normal, prec_embed_only, prec_normal_embed = [], [], []\n",
    "rec_normal, rec_embed_only, rec_normal_embed = [], [], []\n",
    "f1_normal, f1_embed_only, f1_normal_embed = [], [], []\n",
    "\n",
    "col2use_normal = [\"ScheduledDay_day\", \"ScheduledDay_hour\", \"ScheduledDay_minute\", \"ScheduledDay_dayofweek\", \"AppointmentDay_day\", \"AppointmentDay_dayofweek\", \"delta_days\"]\n",
    "# col2use_only_embed = [\"delta_days\"]\n",
    "col2use_only_embed = []\n",
    "col2use_normal_embed = [\"ScheduledDay_day\", \"ScheduledDay_hour\", \"ScheduledDay_minute\", \"ScheduledDay_dayofweek\", \"AppointmentDay_day\", \"AppointmentDay_dayofweek\", \"delta_days\"]\n",
    "\n",
    "for i in range(apppointment_day_vector.shape[-1]):\n",
    "    col2use_only_embed.append(\"latent_var\" + str(i + 1) + \"_scheduled\")\n",
    "    col2use_normal_embed.append(\"latent_var\" + str(i + 1) + \"_scheduled\")\n",
    "    col2use_only_embed.append(\"latent_var\" + str(i + 1) + \"_appointment\")\n",
    "    col2use_normal_embed.append(\"latent_var\" + str(i + 1) + \"_appointment\")\n",
    "    col2use_only_embed.append(\"latent_var\" + str(i + 1) + \"_delta\")\n",
    "    col2use_normal_embed.append(\"latent_var\" + str(i + 1) + \"_delta\")\n",
    "\n",
    "for _ in range(25):\n",
    "    # shuffle the samples\n",
    "    df_test = df.sample(n = len(df))\n",
    "    df_test = df_test.reset_index(drop = True)\n",
    "    df_valid = df_test.sample(frac = 0.3)\n",
    "    df_train = df_test.drop(df_valid.index)\n",
    "\n",
    "    X_train_normal = df_train[col2use_normal].values\n",
    "    X_valid_normal = df_valid[col2use_normal].values\n",
    "\n",
    "    X_train_only_embed = df_train[col2use_only_embed].values\n",
    "    X_valid_only_embed = df_valid[col2use_only_embed].values\n",
    "\n",
    "    X_train_normal_embed = df_train[col2use_normal_embed].values\n",
    "    X_valid_normal_embed = df_valid[col2use_normal_embed].values\n",
    "\n",
    "    y_train = df_train[\"OUTPUT_LABEL\"].values\n",
    "    y_valid = df_valid[\"OUTPUT_LABEL\"].values\n",
    "\n",
    "    # creation\n",
    "    rf_normal = RandomForestClassifier(max_depth = 5, n_estimators=100, random_state = 42)\n",
    "    rf_only_embed = RandomForestClassifier(max_depth = 5, n_estimators=100, random_state = 42)\n",
    "    rf_normal_embed = RandomForestClassifier(max_depth = 5, n_estimators=100, random_state = 42)\n",
    "\n",
    "    # training\n",
    "    rf_normal.fit(X_train_normal, y_train)\n",
    "    rf_only_embed.fit(X_train_only_embed, y_train)\n",
    "    rf_normal_embed.fit(X_train_normal_embed, y_train)\n",
    "\n",
    "    y_normal_valid_preds = rf_normal.predict_proba(X_valid_normal)[:,1]\n",
    "    y_only_embed_valid_preds = rf_only_embed.predict_proba(X_valid_only_embed)[:,1]\n",
    "    y_normal_embed_valid_preds = rf_normal_embed.predict_proba(X_valid_normal_embed)[:,1]\n",
    "\n",
    "    accuracy_norm, precision_norm, recall_norm, f1_norm = print_report(y_valid, y_normal_valid_preds)\n",
    "    accuracy_embed, precision_embed, recall_embed, f1_embed = print_report(y_valid, y_only_embed_valid_preds)\n",
    "    accuracy_norm_embed, precision_norm_embed, recall_norm_embed, f1_norm_embed = print_report(y_valid, y_normal_embed_valid_preds)\n",
    "\n",
    "    acc_normal.append(accuracy_norm)\n",
    "    acc_embed_only.append(accuracy_embed)\n",
    "    acc_normal_embed.append(accuracy_norm_embed)\n",
    "\n",
    "    prec_normal.append(precision_norm)\n",
    "    prec_embed_only.append(precision_embed)\n",
    "    prec_normal_embed.append(precision_norm_embed)\n",
    "\n",
    "    rec_normal.append(recall_norm)\n",
    "    rec_embed_only.append(recall_embed)\n",
    "    rec_normal_embed.append(recall_norm_embed)\n",
    "\n",
    "    f1_normal.append(f1_norm)\n",
    "    f1_embed_only.append(f1_embed)\n",
    "    f1_normal_embed.append(f1_norm_embed)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5f809e317b75bf44c1fc96d1cd9e1131b9cde9a3e6db8a0d8be4378aec00bbc"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
